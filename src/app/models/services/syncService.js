const ftpClient = require('../../../config/db/ftpClient');
const oracleClient = require('../../../config/db/oracleClient');
const csvParser = require('csv-parser');
const fs = require('fs');
const path = require('path');
const unzipper = require('unzipper');
const BATCH_SIZE = 10000;

/**
 * Äá»“ng bá»™ 1 file CSV tá»« FTP vÃ o Oracle DB
 * @param {string} remotePath - ÄÆ°á»ng dáº«n file trÃªn FTP
 * @param {string} localPath - ÄÆ°á»ng dáº«n file local sau táº£i vá»
 * @param {string} tableName - TÃªn báº£ng Oracle
 * @param {string[]} columns - Danh sÃ¡ch cá»™t
 * @param {function} bindsFn - HÃ m nháº­n row, tráº£ vá» máº£ng params dÃ¹ng cho executeMany batch
 * @param {function} mapRowFn - HÃ m xá»­ lÃ½ batch cuá»‘i cÃ¹ng (thÆ°á»ng giá»‘ng bindsFn)
 */
async function syncData(remotePath, localPath, tableName, columns, mapRowFn) {
  const localDir = path.dirname(localPath);
  if (!fs.existsSync(localDir)) {
    fs.mkdirSync(localDir, { recursive: true });
  }

  await ftpClient.connect();
  await ftpClient.downloadFile(remotePath, localPath);
  console.log(`âœ… File downloaded to ${localPath}`);

  const connection = await oracleClient.getConnection();
  const fileStream = fs.createReadStream(localPath);
  const parser = csvParser();
  const rowsBatch = [];

  return new Promise((resolve, reject) => {
    fileStream
      .pipe(parser)
      .on('data', async (row) => {
        parser.pause();
        rowsBatch.push(row);

        if (rowsBatch.length >= BATCH_SIZE) {
          try {
            const binds = rowsBatch.map(mapRowFn);
            await connection.executeMany(
              `INSERT INTO ${tableName} (
                ${columns.join(', ')}
              ) VALUES (
                TO_DATE(:1, 'DD/MM/YYYY'), ${columns.slice(1).map((_, i) => `:${i + 2}`).join(', ')}
              )`,
              binds,
              { autoCommit: false }
            );
            console.log(`âœ… Batch inserted: ${rowsBatch.length} rows`);
            rowsBatch.length = 0;
            parser.resume();
          } catch (err) {
            fileStream.destroy(err);
            reject(err);
          }
        } else {
          parser.resume();
        }
      })
      .on('end', async () => {
        try {
          if (rowsBatch.length > 0) {
            const binds = rowsBatch.map(mapRowFn);
            await connection.executeMany(
              `INSERT INTO ${tableName} (
                ${columns.join(', ')}
              ) VALUES (
                TO_DATE(:1, 'DD/MM/YYYY'), ${columns.slice(1).map((_, i) => `:${i + 2}`).join(', ')}
              )`,
              binds,
              { autoCommit: false }
            );
            console.log(`âœ… Final batch inserted: ${rowsBatch.length} rows`);
          }

          await connection.commit();
          await connection.close();
          await ftpClient.close();

          console.log('âœ… Sync completed');
          resolve();
        } catch (err) {
          reject(err);
        }
      })
      .on('error', err => reject(err));
  });
}

async function downloadAndUnzipFromFTP(remoteZipPath, localZipPath) {
  const localDir = path.dirname(localZipPath);
  if (!fs.existsSync(localDir)) {
    fs.mkdirSync(localDir, { recursive: true });
  }

  // Káº¿t ná»‘i vÃ  táº£i file .zip
  await ftpClient.connect();
  await ftpClient.downloadFile(remoteZipPath, localZipPath);
  console.log(`âœ… File .zip downloaded to ${localZipPath}`);
  await ftpClient.close();
  
  // BGiáº£i nÃ©n
  const extractedFiles = [];
  await new Promise((resolve, reject) => {
    fs.createReadStream(localZipPath)
      .pipe(unzipper.Parse())
      .on('entry', function (entry) {
        const fileName = entry.path;
        const destPath = path.join(localDir, fileName);

        if (fileName.endsWith('.csv')) {
          extractedFiles.push(destPath);
          entry.pipe(fs.createWriteStream(destPath));
        } else {
          entry.autodrain();
        }
      })
      .on('error', reject)
      .on('close', resolve);
  });

  // XoÃ¡ file zip sau khi giáº£i nÃ©n
  try {
    fs.unlinkSync(localZipPath);
    console.log(`ðŸ—‘ï¸ Deleted ZIP file: ${localZipPath}`);
  } catch (err) {
    console.warn(`âš ï¸ Could not delete ZIP file: ${err.message}`);
  }

  // Kiá»ƒm tra káº¿t quáº£
  if (extractedFiles.length === 0) {
    throw new Error('âŒ No CSV file found inside the ZIP');
  }

  console.log(`âœ… Extracted CSV: ${extractedFiles[0]}`);
  return extractedFiles[0];
}

async function importData(localPath, tableName, columns, mapRowFn) {
  const localDir = path.dirname(localPath);
  
  if (!fs.existsSync(localDir)) {
    fs.mkdirSync(localDir, { recursive: true });
  }
  const connection = await oracleClient.getConnection();
  const fileStream = fs.createReadStream(localPath);
  const parser = csvParser({
  mapHeaders: ({ header }) => {
    const cleaned = header.trim().replace(/^"+|"+$/g, ''); // xÃ³a táº¥t cáº£ dáº¥u " Ä‘áº§u cuá»‘i vÃ  trim
    console.log(`Header raw: [${header}] => cleaned: [${cleaned}]`);
    return cleaned;
  }
});

  const placeholders = columns.map((_, i) => `:${i + 1}`).join(', ');
  const rowsBatch = [];

  return new Promise((resolve, reject) => {
    fileStream
      .pipe(parser)
      .on('data', async (row) => {
        parser.pause();
        rowsBatch.push(row);

        if (rowsBatch.length >= BATCH_SIZE) {
          try {
            const binds = rowsBatch.map(mapRowFn);
            await connection.executeMany(
              `INSERT INTO ${tableName} (
                ${columns.join(', ')}
              ) VALUES (${placeholders})`,
              binds,
              { autoCommit: false }
            );
            console.log(`âœ… Batch inserted: ${rowsBatch.length} rows`);
            rowsBatch.length = 0;
            parser.resume();
          } catch (err) {
            fileStream.destroy(err);
            reject(err);
          }
        } else {
          parser.resume();
        }
      })
      .on('end', async () => {
        try {
          if (rowsBatch.length > 0) {
            const binds = rowsBatch.map(mapRowFn);
            await connection.executeMany(
              `INSERT INTO ${tableName} (
                ${columns.join(', ')}
              ) VALUES (${placeholders})`,
              binds,
              { autoCommit: false }
            );
            console.log(`âœ… Final batch inserted: ${rowsBatch.length} rows`);
          }

          await connection.commit();
          await connection.close();

          console.log('âœ… Sync completed');
          resolve();
        } catch (err) {
          reject(err);
        }
      })
      .on('error', err => reject(err));
  });
}

module.exports = { syncData, importData, downloadAndUnzipFromFTP };
